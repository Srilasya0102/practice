# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q87BbNqlz8mwVAnXbf3f_bgDITvf6BDi
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
data=pd.read_csv('/content/DSAI-LVA-DATASET for Quiz.csv')
df=pd.DataFrame(data)
#print(df)
print(df.isnull().sum())
df.drop_duplicates()
la=[]
for i in df['PreviousTestScore']:
  if i in range(90,101):
    la.append('High grade')
  elif i in range(65,90):
    la.append('Low grade')
  else:
    la.append('fail')
data['Target']=la
encoder = OneHotEncoder(sparse_output=False)
one_hot_encoded = encoder.fit_transform(df[["ParentEducation","Pass"]])
one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(["ParentEducation","Pass"]))
df_encoded = pd.concat([df, one_hot_df], axis=1)
df_encoded = df_encoded.drop(["ParentEducation","Pass"], axis=1)
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
data['Target']=le.fit_transform(data['Target'])
y=df_encoded.iloc[:,3:4]
x=df_encoded.drop(['Target'],axis=1)
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = .2)
print(df_encoded)
clf=RandomForestClassifier()
#(('XGB',XGBClassifier()))
clf.fit(x_train,y_train)
pred=clf.predict(x_test)
print(pred)
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(pred,y_test)
print('accuracy=',accuracy)

data['Target'].value_counts()

import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
data=pd.read_csv('/content/DSAI-LVA-DATASET for Quiz.csv')
df=pd.DataFrame(data)
#print(df)
print(df.isnull().sum())
df.drop_duplicates()
la=[]
for i in df['PreviousTestScore']:
  if i in range(90,101):
    la.append('High grade')
  elif i in range(65,90):
    la.append('Low grade')
  else:
    la.append('fail')
data['Target']=la
encoder = OneHotEncoder(sparse_output=False)
one_hot_encoded = encoder.fit_transform(df[["ParentEducation","Pass"]])
one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(["ParentEducation","Pass"]))
df_encoded = pd.concat([df, one_hot_df], axis=1)
df_encoded = df_encoded.drop(["ParentEducation","Pass"], axis=1)
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
data['Target']=le.fit_transform(data['Target'])
y=df_encoded.iloc[:,3:4]
x=df_encoded.drop(['Target'],axis=1)
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = .2)
print(df_encoded)
clf=DecisionTreeClassifier()
#(('XGB',XGBClassifier()))
clf.fit(x_train,y_train)
pred=clf.predict(x_test)
print(pred)
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(pred,y_test)
print('accuracy=',accuracy)

import pandas as pd
import numpy as np
from sklearn.svm import SVC
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
data=pd.read_csv('/content/DSAI-LVA-DATASET for Quiz.csv')
df=pd.DataFrame(data)
#print(df)
print(df.isnull().sum())
df.drop_duplicates()
la=[]
for i in df['PreviousTestScore']:
  if i in range(90,101):
    la.append('High grade')
  elif i in range(65,90):
    la.append('Low grade')
  else:
    la.append('fail')
data['Target']=la
encoder = OneHotEncoder(sparse_output=False)
one_hot_encoded = encoder.fit_transform(df[["ParentEducation","Pass"]])
one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(["ParentEducation","Pass"]))
df_encoded = pd.concat([df, one_hot_df], axis=1)
df_encoded = df_encoded.drop(["ParentEducation","Pass"], axis=1)
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
data['Target']=le.fit_transform(data['Target'])
y=df_encoded.iloc[:,3:4]
x=df_encoded.drop(['Target'],axis=1)
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = .2)
print(df_encoded)
clf=SVC()
#(('XGB',XGBClassifier()))
clf.fit(x_train,y_train)
pred=clf.predict(x_test)
print(pred)
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(pred,y_test)
print('accuracy=',accuracy)

import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
data=pd.read_csv('/content/DSAI-LVA-DATASET for Quiz.csv')
df=pd.DataFrame(data)
#print(df)
print(df.isnull().sum())
df.drop_duplicates()
la=[]
for i in df['PreviousTestScore']:
  if i in range(90,101):
    la.append('High grade')
  elif i in range(65,90):
    la.append('Low grade')
  else:
    la.append('fail')
data['Target']=la
encoder = OneHotEncoder(sparse_output=False)
one_hot_encoded = encoder.fit_transform(df[["ParentEducation","Pass"]])
one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(["ParentEducation","Pass"]))
df_encoded = pd.concat([df, one_hot_df], axis=1)
df_encoded = df_encoded.drop(["ParentEducation","Pass"], axis=1)
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
data['Target']=le.fit_transform(data['Target'])
y=df_encoded.iloc[:,3:4]
x=df_encoded.drop(['Target'],axis=1)
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = .2)
print(df_encoded)
clf=XGBClassifier()
clf.fit(x_train,y_train)
pred=clf.predict(x_test)
print(pred)
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(pred,y_test)
print('accuracy=',accuracy)